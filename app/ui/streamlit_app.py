"""Streamlit UI ì—”íŠ¸ë¦¬í¬ì¸íŠ¸."""

from __future__ import annotations

import json
import os
from pathlib import Path
from typing import Any

import requests
import streamlit as st
from dotenv import load_dotenv
from app.utils.logger import get_logger

load_dotenv()
logger = get_logger(__name__)

FASTAPI_URL_FILE = Path(__file__).resolve().parents[2] / ".fastapi_url"
DEFAULT_FASTAPI_BASE = FASTAPI_URL_FILE.read_text().strip() if FASTAPI_URL_FILE.exists() else ""
MODEL_OPTIONS: dict[str, dict[str, Any]] = {
    "openai": {
        "label": "OpenAI",
        "env": "MODEL_OPENAI",
        "choices": ["gpt-4o", "gpt-4.1", "gpt-4.1-mini"],
    },
    "gemini": {
        "label": "Google Gemini",
        "env": "MODEL_GEMINI",
        "choices": ["gemini-2.5-flash-lite", "gemini-2.0-flash", "gemini-1.5-pro"],
    },
    "anthropic": {
        "label": "Anthropic Claude",
        "env": "MODEL_ANTHROPIC",
        "choices": [
            "claude-haiku-4-5-20251001",
            "claude-3-5-sonnet-20241022",
            "claude-3-opus-20240229",
        ],
    },
    "upstage": {
        "label": "Upstage Solar",
        "env": "MODEL_UPSTAGE",
        "choices": ["solar-mini", "solar-pro", "solar-1-mini-chat"],
    },
    "perplexity": {
        "label": "Perplexity Sonar",
        "env": "MODEL_PERPLEXITY",
        "choices": ["sonar", "sonar-pro", "sonar-reasoning"],
    },
    "mistral": {
        "label": "Mistral",
        "env": "MODEL_MISTRAL",
        "choices": ["mistral-large-latest", "mistral-large-2407", "mistral-small-latest"],
    },
    "groq": {
        "label": "Groq",
        "env": "MODEL_GROQ",
        "choices": ["llama-3.3-70b-versatile"],
    },
    "cohere": {
        "label": "Cohere",
        "env": "MODEL_COHERE",
        "choices": [
            "command-r7b-12-2024",
            "command-a-03-2025",
            "command-a-translate-08-2025",
            "command-a-reasoning-08-2025",
            "command-r-08-2024",
            "command-r-plus-08-2024",
        ],
    },
    "deepseek": {
        "label": "DeepSeek",
        "env": "MODEL_DEEPSEEK",
        "choices": ["deepseek-chat", "deepseek-reasoner"],
    },
}

st.set_page_config(page_title="Compare-AI", page_icon="ðŸ¤–", layout="wide")


def _default_model(provider: str) -> str:
    meta = MODEL_OPTIONS[provider]
    env_value = os.getenv(meta["env"])
    if env_value:
        _log_model_default_if_changed(provider, env_value, "í™˜ê²½ë³€ìˆ˜")
        return env_value
    provider_defaults = {
        "openai": "gpt-4.1-mini",
        "groq": "llama-3.3-70b-versatile",
        "cohere": "command-r7b-12-2024",
        "deepseek": "deepseek-chat",
        "mistral": "mistral-small-latest",
    }
    preferred = provider_defaults.get(provider)
    if preferred and preferred in meta["choices"]:
        _log_model_default_if_changed(provider, preferred, "ê¸°ë³¸")
        return preferred
    # ê°€ë²¼ìš´/ì €ë ´í•œ ëª¨ë¸ì„ ê¸°ë³¸ê°’ìœ¼ë¡œ ì„ íƒ(ë¦¬ìŠ¤íŠ¸ì— ì—†ìœ¼ë©´ ì²« ë²ˆì§¸)
    cheap_candidates = [
        "gpt-4.1-mini",
        "gpt-5-nano",
        "gemini-2.5-flash-lite",
        "claude-3-haiku",
        "solar-mini",
        "sonar-small",
        "mistral-small-3.2",
        "ministral-3-8b",
        "llama-3.3-70b-versatile",
        "command-light",
        "deepseek-chat",
    ]
    for candidate in cheap_candidates:
        if candidate in meta["choices"]:
            _log_model_default_if_changed(provider, candidate, "ì €ê°€í˜•")
            return candidate
    chosen = meta["choices"][0]
    _log_model_default_if_changed(provider, chosen, "ê¸°ë³¸")
    return chosen


def _log_model_default_if_changed(provider: str, model: str, source: str) -> None:
    """ëª¨ë¸ ê¸°ë³¸ê°’ì´ ë°”ë€” ë•Œë§Œ ë¡œê·¸ë¥¼ ë‚¨ê¸´ë‹¤."""

    cache = st.session_state.setdefault("default_model_cache", {})
    last = cache.get(provider)
    if last == model:
        return
    cache[provider] = model
    logger.info("_default_model:ì„ íƒ provider=%s model=%s source=%s", provider, model, source)


def _ensure_model_selections() -> None:
    logger.debug("_ensure_model_selections:ì‹œìž‘")
    defaults = {key: _default_model(key) for key in MODEL_OPTIONS}
    selections = st.session_state.get("model_selections") or {}
    locked = st.session_state.get("model_selections_locked") or {}
    merged = {}
    for key, default in defaults.items():
        if locked.get(key):
            merged[key] = selections.get(key, default)
        else:
            merged[key] = default
    st.session_state["model_selections"] = merged
    st.session_state["model_selections_locked"] = locked
    logger.debug("_ensure_model_selections:ì¢…ë£Œ selections=%s", merged)


def _render_model_selector() -> None:
    logger.debug("_render_model_selector:ì‹œìž‘ model_options=%s", list(MODEL_OPTIONS.keys()))
    _ensure_model_selections()
    st.subheader("ëª¨ë¸ ì„ íƒ")
    for key, meta in MODEL_OPTIONS.items():
        options = list(meta["choices"])
        current = st.session_state["model_selections"].get(key, _default_model(key))
        if current not in options:
            options = [current] + options
        index = options.index(current) if current in options else 0
        selection = st.selectbox(
            f"{meta['label']} ëª¨ë¸",
            options,
            index=index,
            key=f"model_select_{key}",
        )
        if selection != current:
            st.session_state.setdefault("model_selections_locked", {})[key] = True
        st.session_state["model_selections"][key] = selection
    logger.debug("_render_model_selector:ì¢…ë£Œ selections=%s", st.session_state.get("model_selections"))


def _load_base_url() -> str:
    logger.debug("_load_base_url:ì‹œìž‘")
    saved = (
        st.session_state.get("fastapi_base_url")
        or DEFAULT_FASTAPI_BASE
        or os.getenv("FASTAPI_URL", "")
        or st.secrets.get("FASTAPI_URL", "")
    )
    if saved.endswith("/api/ask"):
        base = saved.rsplit("/api/ask", 1)[0]
    else:
        base = saved
    logger.debug("_load_base_url:ì¢…ë£Œ base=%s", base)
    return base


def _get_usage_limit() -> str:
    value = os.getenv("DAILY_USAGE_LIMIT") or "3"
    logger.debug("_get_usage_limit:limit=%s", value)
    return value


def _usage_limit_int() -> int:
    try:
        result = int(_get_usage_limit())
        logger.debug("_usage_limit_int:ì„±ê³µ value=%s", result)
        return result
    except Exception:
        logger.warning("_usage_limit_int:ë³€í™˜ ì‹¤íŒ¨, ê¸°ë³¸ê°’ 3 ì‚¬ìš©")
        return 3


def _sync_usage_from_headers(resp: requests.Response) -> None:
    """ì„œë²„ í—¤ë”ì˜ ì‚¬ìš©ëŸ‰ ì •ë³´ë¥¼ ì„¸ì…˜ì— ë°˜ì˜í•œë‹¤."""

    limit = resp.headers.get("X-Usage-Limit")
    remaining = resp.headers.get("X-Usage-Remaining")
    if limit is not None and limit.isdigit():
        st.session_state["usage_limit"] = int(limit)
    if remaining is not None and remaining.isdigit():
        st.session_state["usage_remaining"] = int(remaining)
    logger.debug(
        "_sync_usage_from_headers:limit=%s remaining=%s", st.session_state.get("usage_limit"), st.session_state.get("usage_remaining")
    )


def _build_history_payload(chat_log: list[dict[str, Any]]) -> list[dict[str, str]]:
    """ê¸°ì¡´ ëŒ€í™” ë¡œê·¸ë¥¼ LangGraph history íŽ˜ì´ë¡œë“œë¡œ ë³€í™˜í•œë‹¤."""

    logger.debug("_build_history_payload:ì‹œìž‘ entries=%d", len(chat_log or []))
    history_payload: list[dict[str, str]] = []
    for entry in chat_log or []:
        q = entry.get("question")
        if q:
            history_payload.append({"role": "user", "content": q})
        model_answers: dict[str, str] = {}
        for model, ans in (entry.get("answers") or {}).items():
            if ans:
                model_answers[model] = ans
        if not model_answers:
            for ev in entry.get("events") or []:
                model = ev.get("model")
                ans = ev.get("answer")
                if model and ans and model not in model_answers:
                    model_answers[model] = ans
        for model, ans in model_answers.items():
            history_payload.append({"role": "assistant", "model": model, "content": ans})
    logger.debug("_build_history_payload:ì¢…ë£Œ payload_len=%d", len(history_payload))
    return history_payload


def _update_usage_after_response(resp: requests.Response, *, admin_mode: bool) -> None:
    """ì‘ë‹µ ì´í›„ ì‚¬ìš©ëŸ‰ ì¹´ìš´í„°ë¥¼ ê°±ì‹ í•œë‹¤."""

    logger.debug("_update_usage_after_response:ì‹œìž‘ admin_mode=%s status=%s", admin_mode, resp.status_code)
    if admin_mode:
        st.session_state["usage_remaining"] = None
        return
    if resp.status_code == 429:
        st.session_state["usage_remaining"] = 0
    elif resp.ok:
        if "X-Usage-Remaining" not in resp.headers:
            new_value = max(0, st.session_state.get("usage_remaining", _usage_limit_int()) - 1)
            st.session_state["usage_remaining"] = new_value
    logger.debug(
        "_update_usage_after_response:ì¢…ë£Œ usage_remaining=%s", st.session_state.get("usage_remaining")
    )


def _append_chat_log_entry(
    question: str,
    answers: dict[str, str],
    sources: dict[str, str | None],
    events: list[dict[str, Any]],
) -> None:
    """ëŒ€í™” ë¡œê·¸ì— ìƒˆ ì—”íŠ¸ë¦¬ë¥¼ ì¶”ê°€í•œë‹¤."""

    logger.debug("_append_chat_log_entry:ì‹œìž‘ question=%s answers=%d events=%d", question, len(answers), len(events))
    st.session_state["chat_log"].append(
        {
            "question": question,
            "answers": answers,
            "sources": sources,
            "events": events,
        }
    )
    logger.debug("_append_chat_log_entry:ì¢…ë£Œ total=%d", len(st.session_state["chat_log"]))


def _status_to_emoji(status_val: Any) -> str:
    """ìƒíƒœ ì½”ë“œ/ë¬¸ìžì—´ì„ ì´ëª¨ì§€ë¡œ ë³€í™˜í•œë‹¤."""

    code = None
    if isinstance(status_val, dict):
        code = status_val.get("status")
    elif isinstance(status_val, (int, str)):
        code = status_val

    if isinstance(code, str):
        code_lower = code.lower()
        if code_lower.isdigit():
            code = int(code_lower)
        elif "error" in code_lower or "fail" in code_lower or "exception" in code_lower:
            return "âŒ"
        elif "timeout" in code_lower or "rate" in code_lower:
            return "âš ï¸"
        elif "ok" in code_lower or "success" in code_lower:
            return "âœ…"

    try:
        code_int = int(code) if code is not None else None
    except Exception:
        code_int = None
    if code_int is None:
        return "â”"
    if code_int >= 500:
        return "âŒ"
    if code_int >= 400:
        return "âš ï¸"
    return "âœ…"


def _is_error_status(status_val: Any) -> bool:
    """ìƒíƒœ ì½”ë“œ/ë¬¸ìžì—´ì´ ì˜¤ë¥˜ì¸ì§€ íŒë³„í•œë‹¤."""

    code = None
    if isinstance(status_val, dict):
        code = status_val.get("status")
    elif isinstance(status_val, (int, str)):
        code = status_val

    if isinstance(code, str):
        lower = code.lower()
        if lower.isdigit():
            code = int(lower)
        elif "error" in lower or "fail" in lower or "exception" in lower:
            return True
        elif "timeout" in lower or "rate" in lower:
            return True

    try:
        code_int = int(code) if code is not None else None
    except Exception:
        code_int = None
    if code_int is None:
        return False
    result = code_int >= 400
    return result


def _format_response_meta(meta: dict[str, Any] | None) -> str | None:
    """ì‘ë‹µ ë©”íƒ€ë¥¼ í•œ ì¤„ ìš”ì•½ìœ¼ë¡œ ë§Œë“ ë‹¤."""

    if not meta:
        return None
    parts: list[str] = []
    model_name = meta.get("model_name")
    if model_name:
        parts.append(f"ëª¨ë¸: {model_name}")
    finish_reason = meta.get("finish_reason") or meta.get("stop_reason")
    if finish_reason:
        parts.append(f"ì¢…ë£Œ: {finish_reason}")
    refusal = meta.get("refusal")
    if refusal:
        parts.append(f"ê±°ë¶€: {refusal}")
    prompt_feedback = meta.get("prompt_feedback")
    if isinstance(prompt_feedback, dict):
        block_reason = prompt_feedback.get("block_reason")
        if block_reason is not None:
            parts.append(f"ì•ˆì „í”¼ë“œë°±: {block_reason}")
    token_usage = meta.get("token_usage")
    if isinstance(token_usage, dict):
        input_tokens = token_usage.get("input_tokens")
        output_tokens = token_usage.get("output_tokens")
        total_tokens = token_usage.get("total_tokens")
        if any(v is not None for v in (input_tokens, output_tokens, total_tokens)):
            parts.append(f"í† í°: {input_tokens}/{output_tokens}/{total_tokens}")
    if not parts:
        return None
    return " | ".join(parts)


def _render_sources_from_meta(meta: dict[str, Any] | None) -> bool:
    """ë©”íƒ€ì— í¬í•¨ëœ ì¶œì²˜ë¥¼ í‘œì‹œí•˜ê³ , í‘œì‹œ ì—¬ë¶€ë¥¼ ë°˜í™˜í•œë‹¤."""

    if not meta:
        return False
    sources = meta.get("sources")
    if not isinstance(sources, list) or not sources:
        return False
    st.caption("ì¶œì²˜:")
    st.markdown("\n".join(f"- {src}" for src in sources))
    return True


def _render_auth_section(base_url: str) -> None:
    """ë¡œê·¸ì¸/íšŒì›ê°€ìž… UIë¥¼ ë Œë”ë§í•œë‹¤."""

    logger.debug("_render_auth_section:ì‹œìž‘ base_url=%s", base_url)
    st.header("ë¡œê·¸ì¸ ë˜ëŠ” íšŒì›ê°€ìž…")
    email = st.text_input("ì´ë©”ì¼")
    password = st.text_input("ë¹„ë°€ë²ˆí˜¸", type="password")
    col1, col2 = st.columns(2)
    with col1:
        if st.button("íšŒì›ê°€ìž…"):
            if not base_url:
                st.error("FastAPI Base URLì„ ìž…ë ¥í•˜ì„¸ìš”.")
            elif not email or not password:
                st.warning("ì´ë©”ì¼/ë¹„ë°€ë²ˆí˜¸ë¥¼ ìž…ë ¥í•˜ì„¸ìš”.")
            else:
                try:
                    resp = requests.post(
                        f"{base_url}/auth/register",
                        json={"email": email, "password": password},
                        timeout=15,
                    )
                    st.write(f"íšŒì›ê°€ìž… ìƒíƒœ: {resp.status_code}")
                    st.json(resp.json())
                except Exception as exc:
                    logger.error("_render_auth_section:íšŒì›ê°€ìž… ì‹¤íŒ¨ email=%s err=%s", email, exc)
                    st.error(f"íšŒì›ê°€ìž… ì‹¤íŒ¨: {exc}")
    with col2:
        if st.button("ë¡œê·¸ì¸"):
            if not base_url:
                st.error("FastAPI Base URLì„ ìž…ë ¥í•˜ì„¸ìš”.")
            elif not email or not password:
                st.warning("ì´ë©”ì¼/ë¹„ë°€ë²ˆí˜¸ë¥¼ ìž…ë ¥í•˜ì„¸ìš”.")
            else:
                try:
                    resp = requests.post(
                        f"{base_url}/auth/login",
                        json={"email": email, "password": password},
                        timeout=15,
                    )
                    data = resp.json()
                    st.write(f"ë¡œê·¸ì¸ ìƒíƒœ: {resp.status_code}")
                    if resp.ok and data.get("access_token"):
                        token = f"{data.get('token_type', 'bearer')} {data['access_token']}"
                        st.session_state["auth_token"] = token
                        st.session_state["auth_user"] = data.get("user")
                        st.success("ë¡œê·¸ì¸ ì„±ê³µ: í† í° ì €ìž¥ ì™„ë£Œ")
                        st.rerun()
                    st.json(data)
                except Exception as exc:
                    logger.error("_render_auth_section:ë¡œê·¸ì¸ ì‹¤íŒ¨ email=%s err=%s", email, exc)
                    st.error(f"ë¡œê·¸ì¸ ì‹¤íŒ¨: {exc}")
    logger.debug("_render_auth_section:ì¢…ë£Œ")
    st.stop()


def _render_chat_history(chat_log: list[dict[str, Any]]) -> None:
    """ê¸°ì¡´ ëŒ€í™” ë¡œê·¸ë¥¼ ì±—ë´‡ í˜•ì‹ìœ¼ë¡œ í‘œì‹œí•œë‹¤."""

    logger.debug("_render_chat_history:ì‹œìž‘ entries=%d", len(chat_log or []))
    if not chat_log:
        st.info("ì•„ì§ ëŒ€í™”ê°€ ì—†ìŠµë‹ˆë‹¤. ì§ˆë¬¸ì„ ìž…ë ¥í•´ë³´ì„¸ìš”.")
        return

    for item in chat_log:
        with st.chat_message("user"):
            st.write(item.get("question"))
        answers = item.get("answers") or {}
        sources = item.get("sources") or {}
        events = item.get("events") or []
        # ëª¨ë¸ë³„ ìƒíƒœ/ì‹œê°„ ë©”íƒ€ êµ¬ì„±
        event_meta: dict[str, dict[str, Any]] = {}
        for ev in events:
            model = ev.get("model")
            if not model:
                continue
            event_meta[model] = {
                "status": ev.get("status"),
                "elapsed_ms": ev.get("elapsed_ms"),
                "response_meta": ev.get("response_meta"),
            }
        with st.chat_message("assistant"):
            if answers:
                for model, answer in answers.items():
                    meta = event_meta.get(model) or {}
                    status = meta.get("status")
                    elapsed_ms = meta.get("elapsed_ms")
                    response_meta = meta.get("response_meta")
                    emoji = _status_to_emoji(status)
                    elapsed_txt = f"{elapsed_ms/1000:.1f}s" if elapsed_ms is not None else "-"
                    st.markdown(f"{emoji} **{model}** â±ï¸ {elapsed_txt}")
                    st.write(answer)
                    meta_text = _format_response_meta(response_meta)
                    if meta_text:
                        st.caption(meta_text)
                    src = sources.get(model)
                    if not _render_sources_from_meta(response_meta):
                        if model == "Perplexity":
                            st.caption(f"ì¶œì²˜: {src or 'ì œê³µë˜ì§€ ì•ŠìŒ'}")
                        elif src:
                            st.caption(f"ì¶œì²˜: {src}")
            elif events:
                st.caption("ì‘ë‹µ ìŠ¤íŠ¸ë¦¼")
                for ev in events:
                    model = ev.get("model") or "unknown"
                    ans = ev.get("answer")
                    src = ev.get("source")
                    status = ev.get("status") or {}
                    elapsed = ev.get("elapsed_ms")
                    response_meta = ev.get("response_meta")
                    elapsed_txt = f"{elapsed/1000:.1f}s" if elapsed is not None else "-"
                    emoji = _status_to_emoji(status)
                    st.write(f"{emoji} [{model}] {ans}")
                    st.caption(f"â±ï¸ {elapsed_txt}")
                    meta_text = _format_response_meta(response_meta)
                    if meta_text:
                        st.caption(meta_text)
                    if not _render_sources_from_meta(response_meta):
                        if model == "Perplexity":
                            st.caption(f"ì¶œì²˜: {src or 'ì œê³µë˜ì§€ ì•ŠìŒ'}")
                        elif src:
                            st.caption(f"ì¶œì²˜: {src}")
    logger.debug("_render_chat_history:ì¢…ë£Œ")


def _render_connection_status(base_url: str) -> None:
    """API ì—°ê²° ìƒíƒœë¥¼ ê°„ë‹¨ížˆ í‘œì‹œí•œë‹¤."""

    logger.debug("_render_connection_status:ì‹œìž‘ base_url=%s", base_url)
    status_box = st.empty()
    if not base_url:
        status_box.warning("FastAPI URLì„ ìž…ë ¥í•˜ì„¸ìš”.")
        return
    with st.spinner("API ì—°ê²° í™•ì¸ ì¤‘..."):
        try:
            resp = requests.get(f"{base_url}/health", timeout=5)
            if resp.ok:
                status_box.success("âœ… API ì—°ê²°ë¨")
            else:
                status_box.error(f"âŒ API ì‘ë‹µ ì˜¤ë¥˜ ({resp.status_code})")
        except Exception as exc:  # pragma: no cover - UI í†µì‹  ì˜ˆì™¸
            status_box.error(f"âŒ ì—°ê²° ì‹¤íŒ¨: {exc}")
            logger.error("_render_connection_status:ì‹¤íŒ¨ err=%s", exc)
    logger.debug("_render_connection_status:ì¢…ë£Œ")


def _handle_logout() -> None:
    """ë¡œê·¸ì•„ì›ƒ ì²˜ë¦¬."""

    logger.debug("_handle_logout:ì‹œìž‘")
    st.session_state.pop("auth_token", None)
    st.session_state.pop("auth_user", None)
    st.session_state.pop("usage_remaining", None)
    st.session_state.pop("usage_bypass", None)
    st.session_state.pop("usage_fetched", None)
    st.session_state.pop("chat_log", None)
    st.rerun()


def _send_question(
    question: str,
    ask_url: str,
    headers: dict[str, str],
    turn_value: int,
    history_payload: list[dict[str, str]],
    model_overrides: dict[str, str] | None = None,
) -> None:
    """ì§ˆë¬¸ì„ ì „ì†¡í•˜ê³  ì‘ë‹µì„ ì„¸ì…˜ì— ë°˜ì˜í•œë‹¤."""

    logger.debug("_send_question:ì‹œìž‘ question=%s turn=%s", question, turn_value)
    payload: dict[str, Any] = {"question": question, "turn": turn_value, "history": history_payload}
    if model_overrides:
        payload["models"] = {k: v for k, v in model_overrides.items() if v}
    resp = requests.post(ask_url, headers=headers, json=payload, stream=True, timeout=60)
    _sync_usage_from_headers(resp)

    live_key = f"live_{turn_value}"
    placeholders = {}
    events_acc: list[dict[str, Any]] = []
    answers_acc: dict[str, str] = {}
    sources_acc: dict[str, str | None] = {}

    for line in resp.iter_lines():
        if not line:
            continue
        try:
            parsed = json.loads(line.decode("utf-8"))
        except Exception:
            parsed = line
        if not isinstance(parsed, dict):
            continue
        event_type = parsed.get("type", "partial")
        if event_type == "partial":
            model = parsed.get("model")
            if not model:
                continue
            status = parsed.get("status") or {}
            answer = parsed.get("answer")
            source = parsed.get("source")
            answers_acc[model] = answer
            sources_acc[model] = source
            events_acc.append(
                {
                    "model": model,
                    "answer": answer,
                    "source": source,
                    "status": status,
                    "elapsed_ms": parsed.get("elapsed_ms"),
                    "response_meta": parsed.get("response_meta"),
                }
            )
            if model not in placeholders:
                placeholders[model] = st.empty()
            slot = placeholders[model]
            with slot.container():
                elapsed = parsed.get("elapsed_ms")
                elapsed_txt = f"{elapsed/1000:.1f}s" if elapsed is not None else "-"
                emoji = _status_to_emoji(status)
                st.markdown(f"{emoji} **{model}** â±ï¸ {elapsed_txt}")
                if _is_error_status(status):
                    st.error(answer or "ì‘ë‹µì´ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                else:
                    st.write(answer)
                meta_text = _format_response_meta(parsed.get("response_meta"))
                if meta_text:
                    st.caption(meta_text)
                src = source
                if not _render_sources_from_meta(parsed.get("response_meta")):
                    if model == "Perplexity":
                        st.caption(f"ì¶œì²˜: {src or 'ì œê³µë˜ì§€ ì•ŠìŒ'}")
                    elif src:
                        st.caption(f"ì¶œì²˜: {src}")
        elif event_type == "error":
            model = parsed.get("model") or "unknown"
            message = parsed.get("message") or "ì—ëŸ¬ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
            status = parsed.get("status") or {}
            elapsed = parsed.get("elapsed_ms")
            elapsed_txt = f"{elapsed/1000:.1f}s" if elapsed is not None else "-"
            emoji = _status_to_emoji(status or "error")
            events_acc.append(
                {
                    "model": model,
                    "answer": message,
                    "source": None,
                    "status": status or "error",
                    "elapsed_ms": elapsed,
                    "response_meta": parsed.get("response_meta"),
                }
            )
            if model not in placeholders:
                placeholders[model] = st.empty()
            slot = placeholders[model]
            with slot.container():
                st.markdown(f"{emoji} **{model}** â±ï¸ {elapsed_txt}")
                st.error(message)
        elif event_type == "summary":
            result = parsed.get("result") or {}
            answers_acc = result.get("answers") or answers_acc
            sources_acc = result.get("sources") or sources_acc
            turn = result.get("turn", turn_value)
            max_turns = result.get("max_turns")
            usage_remaining = result.get("usage_remaining")
            if usage_remaining is not None:
                st.session_state["usage_remaining"] = usage_remaining
            _append_chat_log_entry(question, answers_acc, sources_acc, events_acc)
            _update_usage_after_response(resp, admin_mode=st.session_state.get("usage_bypass"))
            logger.info("_send_question:ìš”ì•½ ìˆ˜ì‹  turn=%s max_turns=%s answers=%d", turn, max_turns, len(answers_acc))
            st.rerun()
            return

    # ìš”ì•½ì´ ì•ˆ ì™”ì„ ë•Œë„ ê¸°ë¡ë§Œ ë‚¨ê¹€
    _append_chat_log_entry(question, answers_acc, sources_acc, events_acc)
    _update_usage_after_response(resp, admin_mode=st.session_state.get("usage_bypass"))
    logger.warning("_send_question:ìš”ì•½ ë¯¸ìˆ˜ì‹ , ê¸°ë¡ë§Œ ì €ìž¥")
    st.rerun()


def _send_prompt_eval(
    question: str,
    eval_url: str,
    headers: dict[str, str],
    prompt_payload: str | None,
    active_models: list[str],
) -> None:
    """í”„ë¡¬í”„íŠ¸ í‰ê°€ ìš”ì²­ì„ ì „ì†¡í•˜ê³  ìŠ¤íŠ¸ë¦¼ ì‘ë‹µì„ í‘œì‹œí•œë‹¤."""

    logger.debug("_send_prompt_eval:ì‹œìž‘ question=%s models=%s", question, active_models)
    payload: dict[str, Any] = {"question": question, "models": active_models}
    model_overrides = st.session_state.get("model_selections") or {}
    if model_overrides:
        payload["model_overrides"] = model_overrides
    if prompt_payload:
        payload["prompt"] = prompt_payload
    reference_answer = st.session_state.get("prompt_eval_reference") or ""
    if reference_answer.strip():
        payload["reference_answer"] = reference_answer.strip()

    resp = requests.post(eval_url, headers=headers, json=payload, stream=True, timeout=120)
    placeholders: dict[str, Any] = {}
    events_acc: list[dict[str, Any]] = []
    summary_data: dict[str, Any] | None = None

    for line in resp.iter_lines():
        if not line:
            continue
        try:
            parsed = json.loads(line.decode("utf-8"))
        except Exception:
            parsed = line
        if not isinstance(parsed, dict):
            continue
        event_type = parsed.get("type", "partial")
        if event_type == "partial":
            model = parsed.get("model")
            if not model:
                continue
            status = parsed.get("status") or {}
            answer = parsed.get("answer")
            elapsed = parsed.get("elapsed_ms")
            elapsed_txt = f"{elapsed/1000:.1f}s" if elapsed is not None else "-"
            emoji = _status_to_emoji(status)
            events_acc.append(
                {
                    "model": model,
                    "answer": answer,
                    "source": None,
                    "status": status,
                    "elapsed_ms": elapsed,
                    "response_meta": parsed.get("response_meta"),
                }
            )
            if model not in placeholders:
                placeholders[model] = st.empty()
            with placeholders[model].container():
                st.markdown(f"{emoji} **{model}** â±ï¸ {elapsed_txt}")
                if _is_error_status(status):
                    st.error(answer or "ì‘ë‹µì´ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                else:
                    st.write(answer)
                meta_text = _format_response_meta(parsed.get("response_meta"))
                if meta_text:
                    st.caption(meta_text)
                _render_sources_from_meta(parsed.get("response_meta"))
        elif event_type == "error":
            message = parsed.get("message") or "ì—ëŸ¬ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
            st.error(message)
            logger.error("_send_prompt_eval:ì—ëŸ¬ ì´ë²¤íŠ¸ model=%s message=%s", parsed.get("model"), message)
            events_acc.append(
                {
                    "model": parsed.get("model") or "unknown",
                    "answer": message,
                    "source": None,
                    "status": parsed.get("status") or "error",
                    "elapsed_ms": parsed.get("elapsed_ms"),
                    "response_meta": parsed.get("response_meta"),
                }
            )
        elif event_type == "summary":
            summary_data = parsed.get("result") or {}
            scores = summary_data.get("scores") or []
            avg_score = summary_data.get("avg_score")
            logger.info("_send_prompt_eval:ìš”ì•½ ìˆ˜ì‹  scores=%d avg=%s", len(scores), avg_score)
            st.subheader("ðŸ í‰ê°€ ê²°ê³¼")
            if avg_score is not None:
                st.markdown(f"âœ¨ **í‰ê·  ì ìˆ˜:** {avg_score}")
            if scores:
                evaluations = summary_data.get("evaluations") or []
                # ëª¨ë¸ë³„ í‰ê°€ìž ì ìˆ˜/ê·¼ê±°ë¥¼ ë§¤í•‘
                per_model: dict[str, list[dict[str, Any]]] = {}
                for ev in evaluations:
                    evaluator = ev.get("evaluator")
                    status = ev.get("status") or {}
                    evaluator_model = ""
                    if isinstance(status, dict):
                        evaluator_model = status.get("model") or ""
                    for sc in ev.get("scores", []):
                        target = sc.get("model")
                        if not target:
                            continue
                        per_model.setdefault(target, []).append(
                            {
                                "evaluator": evaluator,
                                "evaluator_model": evaluator_model,
                                "accuracy": sc.get("accuracy"),
                                "completeness": sc.get("completeness"),
                                "clarity": sc.get("clarity"),
                                "score": sc.get("score"),
                                "rationale": sc.get("rationale"),
                            }
                        )
                # ìˆœìœ„/ì ìˆ˜ ìš”ì•½ í‘œ
                sorted_scores = sorted(scores, key=lambda x: x.get("rank") or 999)
                st.markdown("**ìˆœìœ„/ì ìˆ˜ ìš”ì•½**")
                summary_rows = []
                for s in sorted_scores:
                    model = s.get("model")
                    rank = s.get("rank")
                    avg_raw = s.get("score")
                    avg = f"{avg_raw:.2f}" if isinstance(avg_raw, (int, float)) else avg_raw
                    eval_items = per_model.get(model, [])
                    score_list = ", ".join(
                        (
                            f"{item.get('evaluator')}: {item.get('score'):.2f}"
                            if isinstance(item.get("score"), (int, float))
                            else f"{item.get('evaluator')}: {item.get('score')}"
                        )
                        for item in eval_items
                        if item.get("score") is not None
                    )
                    summary_rows.append(
                        {
                            "ìˆœìœ„": rank,
                            "ëª¨ë¸": model,
                            "í‰ê· ì ìˆ˜": avg,
                            "ë°›ì€ ì ìˆ˜": score_list,
                        }
                    )
                if summary_rows:
                    st.table(summary_rows)

                # ëª¨ë¸ë³„ ìƒì„¸(í‰ê°€ìž ê·¼ê±° ë¶„ë¦¬)
                st.markdown("**ëª¨ë¸ë³„ ìƒì„¸ ê·¼ê±°**")
                lines = []
                for s in sorted_scores:
                    model = s.get("model")
                    rank = s.get("rank")
                    avg = s.get("score")
                    st.markdown(f"### {rank}ìœ„ Â· {model} (í‰ê· ì ìˆ˜: {avg})")
                    eval_items = per_model.get(model, [])
                    if eval_items:
                        # í‰ê°€ìžë³„ ì ìˆ˜/ê·¼ê±° í…Œì´ë¸”
                        rationale_rows = []
                        for item in eval_items:
                            rationale_rows.append(
                                {
                                    "í‰ê°€ìž": item.get("evaluator"),
                                    "í‰ê°€ ëª¨ë¸": item.get("evaluator_model"),
                                    "ì •í™•ì„±": (
                                        f"{item.get('accuracy'):.2f}"
                                        if isinstance(item.get("accuracy"), (int, float))
                                        else item.get("accuracy")
                                    ),
                                    "ì™„ì „ì„±": (
                                        f"{item.get('completeness'):.2f}"
                                        if isinstance(item.get("completeness"), (int, float))
                                        else item.get("completeness")
                                    ),
                                    "ëª…ë£Œì„±": (
                                        f"{item.get('clarity'):.2f}"
                                        if isinstance(item.get("clarity"), (int, float))
                                        else item.get("clarity")
                                    ),
                                    "ê°€ì¤‘ì¹˜ ì ìˆ˜": (
                                        f"{item.get('score'):.2f}"
                                        if isinstance(item.get("score"), (int, float))
                                        else item.get("score")
                                    ),
                                    "ê·¼ê±°": item.get("rationale") or "",
                                }
                            )
                        st.table(rationale_rows)
                    elif s.get("rationale"):
                        st.caption(f"- ê·¼ê±°: {s.get('rationale')}")
                    lines.append(f"{rank}ìœ„ | {model} | í‰ê· ì ìˆ˜={avg}")
                    for item in eval_items:
                        lines.append(f"  {item.get('evaluator')}: {item.get('score')} | ê·¼ê±°: {item.get('rationale') or ''}")
                st.markdown("ðŸ“‹ ë³µì‚¬ìš© í…ìŠ¤íŠ¸")
                st.code("\n".join(lines), language="text")
                st.download_button(
                    "ê²°ê³¼ JSON ë‹¤ìš´ë¡œë“œ",
                    data=json.dumps(summary_data, ensure_ascii=False, indent=2),
                    file_name="prompt_eval_result.json",
                    mime="application/json",
                )
            evaluations = summary_data.get("evaluations") or []
            if evaluations:
                with st.expander("ðŸ§  í‰ê°€ìžë³„ ì›ë³¸ ì ìˆ˜/ê·¼ê±° ë³´ê¸°", expanded=False):
                    for ev in evaluations:
                        status = ev.get("status") or {}
                        status_str = ""
                        if isinstance(status, dict):
                            status_str = str(status.get("status") or status)
                        elif status is not None:
                            status_str = str(status)
                        emoji = _status_to_emoji(status)
                        st.markdown(
                            f"{emoji} **í‰ê°€ìž:** {ev.get('evaluator')} | ìƒíƒœ: {status_str} | ëª¨ë¸: "
                            f"{(status.get('model') if isinstance(status, dict) else '')}"
                        )
                        score_list = ev.get("scores") or []
                        for sc in score_list:
                            st.write(f"- ëŒ€ìƒ: {sc.get('model')} | ì ìˆ˜: {sc.get('score')} | ìˆœìœ„: {sc.get('rank')}")
                            if sc.get("rationale"):
                                st.caption(f"  ê·¼ê±°: {sc.get('rationale')}")
                        if ev.get("elapsed_ms") is not None:
                            st.caption(f"ì†Œìš” ì‹œê°„: {ev.get('elapsed_ms')} ms")
        elif event_type == "usage":
            # ì‚¬ìš©ëŸ‰ ë©”íƒ€ëŠ” í‘œì‹œë§Œ ê±´ë„ˆëœ€
            continue

    if summary_data:
        # ê°„ë‹¨í•œ ë¡œê·¸ ì €ìž¥
        st.session_state.setdefault("prompt_eval_log", []).append(
            {
                "question": question,
                "events": events_acc,
                "summary": summary_data,
            }
        )
    logger.debug("_send_prompt_eval:ì¢…ë£Œ")


def main() -> None:
    logger.debug("streamlit_main:ì‹œìž‘")
    st.title("Compare-AI")
    st.caption("ì—¬ëŸ¬ LLM ì¤‘ ë‚´ ì§ˆë¬¸ì— ê°€ìž¥ ìž˜ ë‹µí•˜ëŠ” ëª¨ë¸ì„ ì°¾ì•„ë³´ì„¸ìš”.")

    with st.sidebar:
        base_url = _load_base_url().rstrip("/")
        st.session_state["fastapi_base_url"] = base_url
        st.text_input("FastAPI URL", value=base_url or "í™˜ê²½ë³€ìˆ˜/íŒŒì¼ë¡œ ì„¤ì •í•˜ì„¸ìš”", disabled=True)
        if not base_url:
            st.error("FASTAPI_URL í™˜ê²½ë³€ìˆ˜ë‚˜ .fastapi_url íŒŒì¼ë¡œ ë°±ì—”ë“œ ì£¼ì†Œë¥¼ ì„¤ì •í•˜ì„¸ìš”.")
            st.stop()
        _render_connection_status(base_url)
        _render_model_selector()

    ask_url = f"{base_url}/api/ask" if base_url else ""
    eval_url = f"{base_url}/api/prompt-eval" if base_url else ""

    # ì¸ì¦/íšŒì›ê°€ìž… ë·°
    if not st.session_state.get("auth_token"):
        _render_auth_section(base_url)

    # ì„¸ì…˜ ê¸°ë³¸ê°’
    if "usage_remaining" not in st.session_state:
        st.session_state["usage_remaining"] = _usage_limit_int()
    if "usage_bypass" not in st.session_state:
        st.session_state["usage_bypass"] = False
    if "chat_log" not in st.session_state:
        st.session_state["chat_log"] = []
    if "prompt_eval_log" not in st.session_state:
        st.session_state["prompt_eval_log"] = []

    # ë¡œê·¸ì¸ í›„ ìµœì´ˆ 1íšŒ ì‚¬ìš©ëŸ‰ ì¡°íšŒ
    if st.session_state.get("auth_token") and "usage_fetched" not in st.session_state:
        usage_url = f"{base_url}/usage"
        try:
            resp = requests.get(usage_url, headers={"Authorization": st.session_state["auth_token"]}, timeout=5)
            data = resp.json()
            if resp.ok:
                remaining_val = data.get("remaining")
                if data.get("bypass"):
                    st.session_state["usage_remaining"] = None
                    st.session_state["usage_bypass"] = True
                elif isinstance(remaining_val, int):
                    st.session_state["usage_remaining"] = remaining_val
                    st.session_state["usage_bypass"] = False
            st.session_state["usage_fetched"] = True
        except Exception:
            st.session_state["usage_fetched"] = True
    if user := st.session_state.get("auth_user"):
        st.caption(f"ë¡œê·¸ì¸ë¨: {user.get('email')}")
    if st.session_state.get("usage_bypass"):
        st.caption("ê´€ë¦¬ìž ê¶Œí•œ í™œì„±í™” (ì¼ì¼ ì œí•œ ì—†ìŒ)")
    remaining = st.session_state.get("usage_remaining")
    if remaining is None:
        st.success("ë‚¨ì€ ì¼ì¼ ì‚¬ìš© íšŸìˆ˜: ë¬´ì œí•œ (ê´€ë¦¬ìž ëª¨ë“œ)")
    elif remaining == 0:
        st.error("ë‚¨ì€ ì¼ì¼ ì‚¬ìš© íšŸìˆ˜: **0íšŒ** (ê´€ë¦¬ìž ìš°íšŒ í•„ìš”)")
    else:
        st.info(f"ë‚¨ì€ ì¼ì¼ ì‚¬ìš© íšŸìˆ˜: **{remaining}íšŒ** (ê´€ë¦¬ìž ìš°íšŒ ì‹œ ì œí•œ ì—†ìŒ)")
    if st.button("ë¡œê·¸ì•„ì›ƒ"):
        _handle_logout()

    logger.debug("streamlit_main:ì¢…ë£Œ")

    tab_compare, tab_prompt = st.tabs(["ëª¨ë¸ ë¹„êµ", "í”„ë¡¬í”„íŠ¸ í‰ê°€"])

    with tab_compare:
        st.header("ëŒ€í™”")
        _render_chat_history(st.session_state["chat_log"])
        show_chat_graph = st.toggle("ê·¸ëž˜í”„ ë³´ê¸° (Chat Graph)", value=False)

        question = st.chat_input("ì§ˆë¬¸ì„ ìž…ë ¥í•˜ì„¸ìš”...")

        if question:
            if not ask_url:
                st.error("FastAPI Base URLì„ ì„¤ì •í•´ì£¼ì„¸ìš”.")
                return
            headers = {"Content-Type": "application/json"}
            if token := st.session_state.get("auth_token"):
                headers["Authorization"] = token
            history_payload = _build_history_payload(st.session_state.get("chat_log", []))
            model_overrides = st.session_state.get("model_selections")
            turn_value = len(st.session_state.get("chat_log", [])) + 1

            with st.spinner("ëª¨ë¸ ë¹„êµ ì¤‘..."):
                try:
                    _send_question(question, ask_url, headers, turn_value, history_payload, model_overrides=model_overrides)
                except Exception as exc:  # pragma: no cover - UI ì˜ˆì™¸
                    st.error(f"ìš”ì²­ ì‹¤íŒ¨: {exc}")
        if show_chat_graph:
            st.subheader("Chat Graph")
            chat_dot = """
            digraph G {
              rankdir=LR;
              Q [label="User Question", shape=box];
              INIT [label="init_question", shape=box];
              OAI [label="call_openai"];
              GEM [label="call_gemini"];
              ANT [label="call_anthropic"];
              PPLX [label="call_perplexity"];
              UPS [label="call_upstage"];
              MIS [label="call_mistral"];
              GRQ [label="call_groq"];
              COH [label="call_cohere"];
              DS [label="call_deepseek"];
              END1 [label="END", shape=Msquare];
              Q -> INIT;
              INIT -> OAI [label="fan-out"];
              INIT -> GEM;
              INIT -> ANT;
              INIT -> PPLX;
              INIT -> UPS;
              INIT -> MIS;
              INIT -> GRQ;
              INIT -> COH;
              INIT -> DS;
              OAI -> END1;
              GEM -> END1;
              ANT -> END1;
              PPLX -> END1;
              UPS -> END1;
              MIS -> END1;
              GRQ -> END1;
              COH -> END1;
              DS -> END1;
            }
            """
            st.graphviz_chart(chat_dot)

    with tab_prompt:
        st.header("í”„ë¡¬í”„íŠ¸ í‰ê°€")
        st.write("ëª¨ë¸ë³„ í”„ë¡¬í”„íŠ¸ë¥¼ ë‹¤ë¥´ê²Œ ì ìš©í•´ ì‘ë‹µì„ ë°›ê³ , ê³ ì • í‰ê°€ëª¨ë¸ë¡œ ë¸”ë¼ì¸ë“œ í‰ê°€í•©ë‹ˆë‹¤.")
        show_eval_graph = st.toggle("ê·¸ëž˜í”„ ë³´ê¸° (Prompt Eval Graph)", value=False)
        if not eval_url:
            st.error("FastAPI Base URLì„ ì„¤ì •í•´ì£¼ì„¸ìš”.")
            return
        headers = {"Content-Type": "application/json"}
        if token := st.session_state.get("auth_token"):
            headers["Authorization"] = token

        active_models = st.multiselect(
            "í‰ê°€í•  ëª¨ë¸ ì„ íƒ",
            options=list(MODEL_OPTIONS.keys()),
            default=list(MODEL_OPTIONS.keys()),
        )
        question_eval = st.text_area("ì§ˆë¬¸", placeholder="ë¹„êµí•  ì§ˆë¬¸ì„ ìž…ë ¥í•˜ì„¸ìš”", height=100)

        default_prompt = """[Question]
{question}

ë‹µë³€ì€ í•œêµ­ì–´ë¡œ ìž‘ì„±í•˜ì„¸ìš”."""
        st.markdown("ê³µí†µ í”„ë¡¬í”„íŠ¸ (ë¯¸ìž…ë ¥ ì‹œ ê¸°ë³¸ê°’ ì‚¬ìš©)")
        prompt_val = st.text_area(
            "í”„ë¡¬í”„íŠ¸",
            key="prompt_common",
            value=default_prompt,
            placeholder="[Question]\n{question}\n\në‹µë³€ì€ í•œêµ­ì–´ë¡œ ìž‘ì„±í•˜ì„¸ìš”.",
            height=120,
        )
        st.markdown("ì„ íƒì‚¬í•­: ëª¨ë²” ë‹µë³€ ì˜ˆì‹œ")
        st.text_area(
            "[ì„ íƒ] ëª¨ë²”ë‹µë³€ ì˜ˆì‹œ",
            key="prompt_eval_reference",
            placeholder="ì˜ˆì‹œ ëª¨ë²”ë‹µë³€ì„ ìž…ë ¥í•˜ì„¸ìš”.",
            height=120,
        )

        if st.button("í”„ë¡¬í”„íŠ¸ í‰ê°€ ì‹¤í–‰", disabled=not question_eval or not active_models):
            with st.spinner("í”„ë¡¬í”„íŠ¸ í‰ê°€ ì‹¤í–‰ ì¤‘..."):
                try:
                    active_labels = [MODEL_OPTIONS[k]["label"] for k in active_models if k in MODEL_OPTIONS]
                    prompt_payload = prompt_val.strip() or None
                    _send_prompt_eval(question_eval, eval_url, headers, prompt_payload, active_labels)
                except Exception as exc:  # pragma: no cover
                    st.error(f"ìš”ì²­ ì‹¤íŒ¨: {exc}")
        if show_eval_graph:
            st.subheader("Prompt Eval Graph")
            eval_dot = """
            digraph G {
              rankdir=LR;
              Q2 [label="Question + Prompt", shape=box];
              OAI_G [label="Generate OpenAI"];
              GEM_G [label="Generate Gemini"];
              ANT_G [label="Generate Anthropic"];
              UPS_G [label="Generate Upstage"];
              PPLX_G [label="Generate Perplexity"];
              MIS_G [label="Generate Mistral"];
              GRQ_G [label="Generate Groq"];
              COH_G [label="Generate Cohere"];
              DS_G [label="Generate DeepSeek"];

              Q2 -> OAI_G;
              Q2 -> GEM_G;
              Q2 -> ANT_G;
              Q2 -> UPS_G;
              Q2 -> PPLX_G;
              Q2 -> MIS_G;
              Q2 -> GRQ_G;
              Q2 -> COH_G;
              Q2 -> DS_G;

              OAI_E [label="Eval by OpenAI (latest)"];
              GEM_E [label="Eval by Gemini (latest)"];
              ANT_E [label="Eval by Anthropic (latest)"];
              UPS_E [label="Eval by Upstage (latest)"];
              PPLX_E [label="Eval by Perplexity (latest)"];
              MIS_E [label="Eval by Mistral (latest)"];
              GRQ_E [label="Eval by Groq (latest)"];
              COH_E [label="Eval by Cohere (latest)"];
              DS_E [label="Eval by DeepSeek (latest)"];

              OAI_G -> OAI_E;
              GEM_G -> GEM_E;
              ANT_G -> ANT_E;
              UPS_G -> UPS_E;
              PPLX_G -> PPLX_E;
              MIS_G -> MIS_E;
              GRQ_G -> GRQ_E;
              COH_G -> COH_E;
              DS_G -> DS_E;

              SUM [label="Summary", shape=Msquare];
              OAI_E -> SUM;
              GEM_E -> SUM;
              ANT_E -> SUM;
              UPS_E -> SUM;
              PPLX_E -> SUM;
              MIS_E -> SUM;
              GRQ_E -> SUM;
              COH_E -> SUM;
              DS_E -> SUM;
            }
            """
            st.graphviz_chart(eval_dot)


if __name__ == "__main__":
    main()
